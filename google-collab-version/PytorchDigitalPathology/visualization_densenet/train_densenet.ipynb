{
    "cells": [{
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "-qrmsskFlq-P"
            },
            "outputs": [],
            "source": ["dataname=\"synthetic\"\n", "gpuid=0\n", "\n", "# --- densenet params\n", "#these parameters get fed directly into the densenet class, and more description of them can be discovered there\n", "n_classes= 2    #number of classes in the data mask that we'll aim to predict\n", "in_channels= 3  #input channel of the data, RGB = 3\n", "\n", "\n", "growth_rate=8 \n", "block_config=(4, 4, 4, 4)\n", "num_init_features=2\n", "bn_size=4\n", "drop_rate=0\n", "\n", "\n", "\n", "# --- training params\n", "batch_size=64\n", "patch_size=224 #currently, this needs to be 224 due to densenet architecture\n", "num_epochs = 10\n", "phases = [\"train\",\"val\"] #how many phases did we create databases for?\n", "validation_phases= [\"val\"] #when should we do valiation? note that validation is *very* time consuming, so as opposed to doing for both training and validation, we do it only for vlaidation at the end of the epoch\n", "                           #additionally, using simply [], will skip validation entirely, drastically speeding things up"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "hbONSWUZmBPc"
            },
            "outputs": [],
            "source": ["!pip install tensorboardX"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "l3SBSLiUl66L"
            },
            "outputs": [],
            "source": ["import time\n", "import math\n", "import tables\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.metrics import confusion_matrix\n", "\n", "import torch\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torchvision.models import DenseNet\n", "\n", "from tensorboardX import SummaryWriter"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "oOkBnrWemcnU"
            },
            "outputs": [],
            "source": ["#helper function for pretty printing of current time and remaining time\n", "def asMinutes(s):\n", "    m = math.floor(s / 60)\n", "    s -= m * 60\n", "    return '%dm %ds' % (m, s)\n", "def timeSince(since, percent):\n", "    now = time.time()\n", "    s = now - since\n", "    es = s / (percent+.00001)\n", "    rs = es - s\n", "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Wic1EZuEmgBS"
            },
            "outputs": [],
            "source": ["#specify if we should use a GPU (cuda) or only the CPU\n", "print(torch.cuda.get_device_properties(gpuid))\n", "torch.cuda.set_device(gpuid)\n", "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "QocYgRTpmlAx"
            },
            "outputs": [],
            "source": ["#build the model according to the paramters specified above and copy it to the GPU. finally print out the number of trainable parameters\n", " \n", "model = DenseNet(growth_rate=growth_rate, block_config=block_config,\n", "                 num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate, num_classes=n_classes).to(device)\n", "\n", "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "KmuOon65mrfL"
            },
            "outputs": [],
            "source": ["#this defines our dataset class which will be used by the dataloader\n", "class Dataset(object):\n", "    def __init__(self, fname ,img_transform=None):\n", "        #nothing special here, just internalizing the constructor parameters\n", "        self.fname=fname\n", "\n", "        self.img_transform=img_transform\n", "        \n", "        with tables.open_file(self.fname,'r') as db:\n", "            self.classsizes=db.root.classsizes[:]\n", "            self.nitems=db.root.imgs.shape[0]\n", "        \n", "        self.imgs = None\n", "        self.labels = None\n", "        \n", "    def __getitem__(self, index):\n", "        #opening should be done in __init__ but seems to be\n", "        #an issue with multithreading so doing here. need to do it everytime, otherwise hdf5 crashes\n", "\n", "        with tables.open_file(self.fname,'r') as db:\n", "            self.imgs=db.root.imgs\n", "            self.labels=db.root.labels\n", "\n", "            #get the requested image\n", "            img = self.imgs[index,::]\n", "            img = img[:,:,None].repeat(3,axis=2) #convert to 3 channel RGB\n", "            label = self.labels[index] \n", "        \n", "        img_new = img\n", "        \n", "        if self.img_transform is not None:\n", "            img_new = self.img_transform(img)\n", "\n", "        return img_new, label, img\n", "    def __len__(self):\n", "        return self.nitems"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "nBdqTVpFnBV6"
            },
            "outputs": [],
            "source": ["from google.colab import drive\n", "drive.mount('/gdrive')\n", "%cd /gdrive"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "l4r5TdRQioZN"
            },
            "outputs": [],
            "source": [""]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "S9m96cSdnI6S"
            },
            "outputs": [],
            "source": ["%cd My\\ Drive/PytorchDigitalPathology/google-collab-version/PytorchDigitalPathology/visualization_densenet/"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "tCvA2dqUmvSa"
            },
            "outputs": [],
            "source": ["img_transform = transforms.Compose([\n", "     transforms.ToPILImage(),\n", "    transforms.RandomVerticalFlip(),\n", "    transforms.RandomHorizontalFlip(),\n", "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color\n", "    transforms.ToTensor()\n", "    ])\n", "\n", "\n", "dataset={}\n", "dataLoader={}\n", "for phase in phases: #now for each of the phases, we're creating the dataloader\n", "                     #interestingly, given the batch size, i've not seen any improvements from using a num_workers>0\n", "    \n", "    dataset[phase]=Dataset(f\"./{dataname}_{phase}.pytable\", img_transform=img_transform)\n", "    dataLoader[phase]=DataLoader(dataset[phase], batch_size=256, \n", "                                shuffle=True, num_workers=0,pin_memory=True) \n", "    print(f\"{phase} dataset size:\\t{len(dataset[phase])}\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "sBRYMO7pnPur"
            },
            "outputs": [],
            "source": ["#visualize a single example to verify that it is correct\n", "(img, label, img_old)=dataset[\"train\"][24]\n", "fig, ax = plt.subplots(1,2, figsize=(10,4))  # 1 row, 2 columns\n", "\n", "#build output showing patch after augmentation and original patch\n", "ax[0].imshow(np.moveaxis(img.numpy(),0,-1))\n", "ax[1].imshow(img_old)\n", "\n", "print(label)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "O47B0UnFnX00"
            },
            "outputs": [],
            "source": ["optim = torch.optim.Adam(model.parameters()) #adam is going to be the most robust, though perhaps not the best performing, typically a good place to start"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "pYNQbdbwnb6Y"
            },
            "outputs": [],
            "source": ["#we have the ability to weight individual classes, in this case we'll do so based on their presense in the trainingset\n", "#to avoid biasing any particular class\n", "nclasses = dataset[\"train\"].classsizes.shape[0]\n", "class_weight=dataset[\"train\"].classsizes\n", "class_weight = torch.from_numpy(1-class_weight/class_weight.sum()).type('torch.FloatTensor').to(device)\n", "\n", "print(class_weight) #show final used weights, make sure that they're reasonable before continouing\n", "criterion = torch.nn.CrossEntropyLoss(weight = class_weight)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "xdR7943Bo1Cm"
            },
            "outputs": [],
            "source": ["!pip install line_profiler"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "WCyT3QbfngTf"
            },
            "outputs": [],
            "source": ["%load_ext line_profiler\n", "#%lprun\n", "# %%prun"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "o4OiRpHNpQyn"
            },
            "outputs": [],
            "source": ["import tensorflow as tf\n", "print(tf.__version__)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "IbMxjk2YpTOw"
            },
            "outputs": [],
            "source": ["%load_ext tensorboard"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "IjgkSFbcpgsO"
            },
            "outputs": [],
            "source": ["def trainnetwork():\n", "    writer=SummaryWriter() #open the tensorboard visualiser\n", "    best_loss_on_test = np.Infinity\n", "\n", "    start_time = time.time()\n", "    for epoch in range(num_epochs):\n", "        #zero out epoch based performance variables \n", "        all_acc = {key: 0 for key in phases} \n", "        all_loss = {key: torch.zeros(0).to(device) for key in phases} #keep this on GPU for greatly improved performance\n", "        cmatrix = {key: np.zeros((n_classes,n_classes)) for key in phases}\n", "\n", "        for phase in phases: #iterate through both training and validation states\n", "\n", "            if phase == 'train':\n", "                model.train()  # Set model to training mode\n", "            else: #when in eval mode, we don't want parameters to be updated\n", "                model.eval()   # Set model to evaluate mode\n", "\n", "            for ii , (X, label, img_orig) in enumerate(dataLoader[phase]): #for each of the batches\n", "                X = X.to(device)  # [Nbatch, 3, H, W]\n", "                label = label.type('torch.LongTensor').to(device)  # [Nbatch, 1] with class indices (0, 1, 2,...n_classes)\n", "\n", "                with torch.set_grad_enabled(phase == 'train'): #dynamically set gradient computation, in case of validation, this isn't needed\n", "                                                                #disabling is good practice and improves inference time\n", "\n", "                    prediction = model(X)  # [Nbatch, Nclass]\n", "                    loss = criterion(prediction, label)\n", "\n", "\n", "                    if phase==\"train\": #in case we're in train mode, need to do back propogation\n", "                        optim.zero_grad()\n", "                        loss.backward()\n", "                        optim.step()\n", "                        train_loss = loss\n", "\n", "\n", "                    all_loss[phase]=torch.cat((all_loss[phase],loss.detach().view(1,-1)))\n", "\n", "                    if phase in validation_phases: #if this phase is part of validation, compute confusion matrix\n", "                        p=prediction.detach().cpu().numpy()\n", "                        cpredflat=np.argmax(p,axis=1).flatten()\n", "                        yflat=label.cpu().numpy().flatten()\n", "\n", "                        cmatrix[phase]=cmatrix[phase]+confusion_matrix(yflat,cpredflat, labels=range(nclasses))\n", "\n", "            all_acc[phase]=(cmatrix[phase]/cmatrix[phase].sum()).trace()\n", "            all_loss[phase] = all_loss[phase].cpu().numpy().mean()\n", "\n", "            #save metrics to tensorboard\n", "            writer.add_scalar(f'{phase}/loss', all_loss[phase], epoch)\n", "            if phase in validation_phases:\n", "                writer.add_scalar(f'{phase}/acc', all_acc[phase], epoch)\n", "                for r in range(nclasses):\n", "                    for c in range(nclasses): #essentially write out confusion matrix\n", "                        writer.add_scalar(f'{phase}/{r}{c}', cmatrix[phase][r][c],epoch)\n", "\n", "        print('%s ([%d/%d] %d%%), train loss: %.4f test loss: %.4f' % (timeSince(start_time, (epoch+1) / num_epochs), \n", "                                                     epoch+1, num_epochs ,(epoch+1) / num_epochs * 100, all_loss[\"train\"], all_loss[\"val\"]),end=\"\")    \n", "\n", "        #if current loss is the best we've seen, save model state with all variables\n", "        #necessary for recreation\n", "        if all_loss[\"val\"] < best_loss_on_test:\n", "            best_loss_on_test = all_loss[\"val\"]\n", "            print(\"  **\")\n", "            state = {'epoch': epoch + 1,\n", "             'model_dict': model.state_dict(),\n", "             'optim_dict': optim.state_dict(),\n", "             'best_loss_on_test': all_loss,\n", "             'n_classes': n_classes,\n", "             'in_channels': in_channels,\n", "             'growth_rate':growth_rate,\n", "             'block_config':block_config,\n", "             'num_init_features':num_init_features,\n", "             'bn_size':bn_size,\n", "             'drop_rate':drop_rate}\n", "\n", "\n", "            torch.save(state, f\"{dataname}_densenet_best_model.pth\")\n", "        else:\n", "            print(\"\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "znBv_8KlqHt7"
            },
            "outputs": [],
            "source": ["#%load_ext line_profiler\n", "%lprun -f trainnetwork trainnetwork()\n"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "CZuJSgbJNvoC"
            },
            "outputs": [],
            "source": ["%tensorboard --logdir runs"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "FR8TRdHwN8_f"
            },
            "outputs": [],
            "source": ["for ii , (X, label, img_orig) in enumerate(dataLoader[phase]):\n", "    print(ii)\n", "    X = X.to(device)"]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "train_densenet.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
