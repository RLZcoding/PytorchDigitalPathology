{
    "cells": [{
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3Ts1DCKKkE8A"
            },
            "outputs": [],
            "source": ["dataname=\"synthetic\"\n", "\n", "patch_size=256 #size of the tiles to put into DB\n", "data_size=[10000,100]\n", "balance=.5\n", "classes=[0,1] #what classes we expect to have in the data, in this case data without boxes and data with boxes\n", "\n", "max_circles=10\n", "max_squares=1\n", "diameter_min=10\n", "diameter_max=50\n", "\n", "phases=[\"train\",\"val\"]"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "PtWu3U3OkKwy"
            },
            "outputs": [],
            "source": ["import random\n", "import tables\n", "import sys\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from PIL import Image, ImageDraw\n", "\n", "\n", "seed = random.randrange(sys.maxsize) #get a random seed so that we can reproducibly do the cross validation setup\n", "random.seed(seed) # set the seed\n", "print(f\"random seed (note down for reproducibility): {seed}\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "tuzRFb9nkL_k"
            },
            "outputs": [],
            "source": ["img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved, this indicates that images will be saved as unsigned int 8 bit, i.e., [0,255]"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "_I4XnD_Zk7Ox"
            },
            "outputs": [],
            "source": ["from google.colab import drive\n", "drive.mount('/gdrive')\n", "%cd /gdrive"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "MwiJANfbV981"
            },
            "outputs": [],
            "source": ["%ls MyDrive/"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "5MzPGzEalQWg"
            },
            "outputs": [],
            "source": ["%cd My\\ Drive/PytorchDigitalPathology/google-collab-version/PytorchDigitalPathology/visualization_densenet/"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jOjsmy4QkU6N"
            },
            "outputs": [],
            "source": ["%matplotlib inline\n", "storage={} #holder for future pytables\n", "\n", "block_shape=np.array((patch_size,patch_size)) #block shape specifies what we'll be saving into the pytable array, here we assume that masks are 1d and images are 3d\n", "\n", "filters=tables.Filters(complevel=6, complib='zlib') #we can also specify filters, such as compression, to improve storage speed\n", "\n", "\n", "for phase,nimgs in zip(phases,data_size): #now for each of the phases, we'll loop through the files\n", "    print(phase)\n", "    \n", "    totals=np.zeros(2) # we can to keep counts of all the classes in for in particular training, since we \n", "\n", "    hdf5_file = tables.open_file(f\"./{dataname}_{phase}.pytable\", mode='w') #open the respective pytable\n", "\n", "\n", "    storage[\"imgs\"]= hdf5_file.create_earray(hdf5_file.root, \"imgs\", img_dtype,  \n", "                                              shape=np.append([0],block_shape), \n", "                                              chunkshape=np.append([1],block_shape),\n", "                                              filters=filters)\n", "    storage[\"labels\"]= hdf5_file.create_earray(hdf5_file.root, \"labels\", img_dtype,  \n", "                                              shape=[0], \n", "                                              chunkshape=[1],\n", "                                              filters=filters)\n", "\n", "    \n", "    for filei in range(nimgs): #now for each of the files\n", "        img=np.zeros((patch_size,patch_size))\n", "        img = Image.fromarray(img)\n", "        draw= ImageDraw.Draw(img)\n", "        \n", "        for i in range(np.random.randint(0,high=max_circles)):\n", "            d=np.random.randint(diameter_min,diameter_max)\n", "            ul=np.random.randint(diameter_min,patch_size-diameter_max,2)\n", "            draw.ellipse(list(np.append(ul,ul+d)),fill=255)\n", "    \n", "\n", "        label=np.random.random()>balance\n", "        if label:\n", "            for i in range(np.random.randint(1,high=max_squares+1)):\n", "                d=np.random.randint(diameter_min,diameter_max)\n", "                ul=np.random.randint(diameter_min,patch_size-diameter_max,2)\n", "                draw.rectangle(list(np.append(ul,ul+d)),fill=255)\n", "                totals[1]+=1\n", "        else:\n", "            totals[0]+=1\n", "            #add square\n", "        \n", "        del draw    \n", "\n", "        storage[\"imgs\"].append(np.array(img)[None,::])\n", "        storage[\"labels\"].append([np.uint8(label)]) #add the filename to the storage array\n", "        \n", "    #lastely, we should store the number of pixels\n", "    npixels=hdf5_file.create_carray(hdf5_file.root, 'classsizes', tables.Atom.from_dtype(totals.dtype), totals.shape)\n", "    npixels[:]=totals\n", "    hdf5_file.close()\n", "    \n", "print(\"done\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ahiyvxyzWI1c"
            },
            "outputs": [],
            "source": [""]
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "make_hdf5_synthetic_circles_and_boxes.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
