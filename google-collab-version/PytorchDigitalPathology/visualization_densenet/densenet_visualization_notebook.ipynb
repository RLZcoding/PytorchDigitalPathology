{
    "cells": [{
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "QbcH2BeFOcTU"
            },
            "outputs": [],
            "source": ["%load_ext autoreload"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jRuYBIzOTCz3"
            },
            "outputs": [],
            "source": ["dataname=\"synthetic\"\n", "gpuid=0\n", "\n", "patch_size=224 #should match the value used to train the network"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "TdGEesc5GcDO"
            },
            "outputs": [],
            "source": ["import torch\n", "print(torch.__version__)\n", "import torchvision\n", "print(torchvision.__version__)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "_VwvUepWTJv8"
            },
            "outputs": [],
            "source": ["print(torch.cuda.get_device_properties(gpuid))\n", "torch.cuda.set_device(gpuid)\n", "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "yxQHyHrMTGgD"
            },
            "outputs": [],
            "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "import tables\n", "import math\n", "\n", "import torch\n", "from torchvision.models import DenseNet\n", "from torch.autograd import Variable\n", "from torchvision import transforms"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "TTnUSjVuTQYo"
            },
            "outputs": [],
            "source": ["from google.colab import drive\n", "drive.mount('/gdrive')\n", "%cd /gdrive"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jBskT1LBTjCg"
            },
            "outputs": [],
            "source": ["%cd My\\ Drive/PytorchDigitalPathology/google-collab-version/PytorchDigitalPathology/visualization_densenet/"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "QHu1NnkSK3R9"
            },
            "outputs": [],
            "source": ["import sys\n", "sys.path.append('./pytorch-cnn-visualizations/src/')\n", "from misc_functions import convert_to_grayscale"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "aSdUTXNkTOB1"
            },
            "outputs": [],
            "source": ["checkpoint = torch.load(f\"{dataname}_densenet_best_model.pth\",  map_location=lambda storage, loc: storage) #load checkpoint to CPU and then put to dev"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "9dVOnqQCTruI"
            },
            "outputs": [],
            "source": ["#load the model, note that the paramters are coming from the checkpoint, since the architecture of the model needs to exactly match the weights saved\n", "\n", "model = DenseNet(growth_rate=checkpoint[\"growth_rate\"], block_config=checkpoint[\"block_config\"],\n", "                 num_init_features=checkpoint[\"num_init_features\"], bn_size=checkpoint[\"bn_size\"], drop_rate=checkpoint[\"drop_rate\"], num_classes=checkpoint[\"n_classes\"]).to(device)\n", "\n", "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")\n", "model.load_state_dict(checkpoint[\"model_dict\"])"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "YHdriSzOTyYU"
            },
            "outputs": [],
            "source": ["phase=\"val\"\n", "db=tables.open_file(f\"./{dataname}_{phase}.pytable\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "RdSUVMLpT1PT"
            },
            "outputs": [],
            "source": ["img_transform = transforms.Compose([\n", "    transforms.ToPILImage(),\n", "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color\n", "    transforms.ToTensor()\n", "    ])"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "WbIBsxNiT4P4"
            },
            "outputs": [],
            "source": ["imgid=19\n", "\n", "img = db.root.imgs[imgid,::]\n", "#label = torch.tensor(db.root.labels[imgid])\n", "label = torch.tensor(np.array(db.root.labels[imgid]))\n", "\n", "img = img[:,:,None].repeat(3,axis=2) #convert to 3 channel\n", "\n", "timg=img_transform(img)\n", "\n", "plt.imshow(img)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "OPbhdfQWT8L5"
            },
            "outputs": [],
            "source": ["model.eval()\n", "\n", "timg = timg.to(device)  # [1, 3, H, W]\n", "label = label.type('torch.LongTensor').to(device)  # [1] with class indices (0, 1)\n", "\n", "output = model(timg[None,::])  \n", "output=output.detach().squeeze().cpu().numpy() #get output and pull it to CPU\n", "    \n", "predlabel=np.argmax(output)\n", "print(f\"class vals: {output}\")\n", "print(f\"actual class: {label}\")\n", "print(f\"predicted class: {predlabel}\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "T-wxRA9EUDgE"
            },
            "outputs": [],
            "source": ["def rescale_grads(map,gradtype=\"all\"):\n", "    if(gradtype==\"pos\"):    #positive\n", "        map = (np.maximum(0, map) / map.max())\n", "    elif gradtype==\"neg\":\n", "        map = (np.maximum(0, -map) / -map.min())\n", "    else:\n", "        map = map - map.min()\n", "        map /= map.max()\n", "    return map"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "4KiSbrprbrBp"
            },
            "outputs": [],
            "source": ["from vanilla_backprop import VanillaBackprop\n", "VBP = VanillaBackprop(model,device)\n", "vanilla_grads = VBP.generate_gradients(timg[None,::], label)\n", "vanilla_grads=np.moveaxis(vanilla_grads,0,-1)\n", "\n", "fig, ax = plt.subplots(3,3, figsize=(20,10))\n", "ax = ax.flatten()\n", "\n", "ax[0].set_title(\"original\")\n", "ax[0].imshow(img)\n", "\n", "ax[1].set_title(\"post transform\")\n", "ax[1].imshow(np.moveaxis(timg.cpu().numpy().squeeze(),0,-1))\n", "\n", "ax[3].set_title(\"all gradients\")\n", "ax[3].imshow(rescale_grads(vanilla_grads,gradtype=\"all\"))\n", "\n", "ax[4].set_title(\"positive gradients\")\n", "ax[4].imshow(rescale_grads(vanilla_grads,gradtype=\"pos\"))\n", "\n", "ax[5].set_title(\"negative gradients\")\n", "ax[5].imshow(rescale_grads(vanilla_grads,gradtype=\"neg\"))\n", "\n", "ax[6].set_title(\"all gradients grayscale\")\n", "ax[6].imshow(convert_to_grayscale(rescale_grads(vanilla_grads,gradtype=\"all\")))\n", "\n", "ax[7].set_title(\"positive gradients grayscale\")\n", "ax[7].imshow(convert_to_grayscale(rescale_grads(vanilla_grads,gradtype=\"pos\")))\n", "\n", "ax[8].set_title(\"negative gradients grayscale\")\n", "ax[8].imshow(convert_to_grayscale(rescale_grads(vanilla_grads,gradtype=\"neg\")))"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ueQb_3SPbxuA"
            },
            "outputs": [],
            "source": ["from guided_backprop import GuidedBackprop\n", "GB=GuidedBackprop(model,device)\n", "gp_grads=GB.generate_gradients(timg[None,::], label)\n", "\n", "\n", "gp_grads=np.moveaxis(gp_grads,0,-1)\n", "\n", "fig, ax = plt.subplots(3,3, figsize=(20,10))\n", "ax = ax.flatten()\n", "\n", "ax[0].set_title(\"original\")\n", "ax[0].imshow(img)\n", "\n", "ax[1].set_title(\"post transform\")\n", "ax[1].imshow(np.moveaxis(timg.cpu().numpy().squeeze(),0,-1))\n", "\n", "ax[3].set_title(\"all gradients\")\n", "ax[3].imshow(rescale_grads(gp_grads,gradtype=\"all\"))\n", "\n", "ax[4].set_title(\"positive gradients\")\n", "ax[4].imshow(rescale_grads(gp_grads,gradtype=\"pos\"))\n", "\n", "ax[5].set_title(\"negative gradients\")\n", "ax[5].imshow(rescale_grads(gp_grads,gradtype=\"neg\"))\n", "\n", "ax[6].set_title(\"all gradients grayscale\")\n", "ax[6].imshow(convert_to_grayscale(rescale_grads(gp_grads,gradtype=\"all\")))\n", "\n", "ax[7].set_title(\"positive gradients grayscale\")\n", "ax[7].imshow(convert_to_grayscale(rescale_grads(gp_grads,gradtype=\"pos\")))\n", "\n", "ax[8].set_title(\"negative gradients grayscale\")\n", "ax[8].imshow(convert_to_grayscale(rescale_grads(gp_grads,gradtype=\"neg\")))"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "WinHVL7jb4BH"
            },
            "outputs": [],
            "source": ["from gradcam import GradCam\n", "\n", "nlayers=len(model.features._modules.items())-1\n", "\n", "fig, ax = plt.subplots(math.ceil(nlayers/4),4, figsize=(20,10))\n", "ax = ax.flatten()\n", "\n", "for layer in range(nlayers):\n", "    grad_cam = GradCam(model, device,target_layer=layer)\n", "    cam = grad_cam.generate_cam(timg[None,::], label)\n", "    ax[layer].imshow(cam)"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "tZFE6MbkcBAL"
            },
            "outputs": [],
            "source": ["from gradcam import GradCam\n", "from guided_gradcam import guided_grad_cam\n", "from guided_backprop import GuidedBackprop\n", "\n", "nlayers=len(model.features._modules.items())-1\n", "\n", "fig, ax = plt.subplots(math.ceil(nlayers/4),4, figsize=(20,10))\n", "ax = ax.flatten()\n", "\n", "for layer in range(nlayers):\n", "    #GradCam\n", "    grad_cam = GradCam(model, device,target_layer=layer)\n", "    cam = grad_cam.generate_cam(timg[None,::], label)\n", "    \n", "    #GuidedBackprop\n", "    GBP = GuidedBackprop(model, device)\n", "    guided_grads = GBP.generate_gradients(timg[None,::], label)\n", "    \n", "    # Guided Grad cam\n", "    cam_gb = guided_grad_cam(cam, guided_grads)\n", "    \n", "    ax[layer].imshow(convert_to_grayscale(np.moveaxis(cam_gb,0,-1)))"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GDJX50s4Kl1Q"
            },
            "outputs": [],
            "source": [""]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "densenet_visualization_notebook.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
