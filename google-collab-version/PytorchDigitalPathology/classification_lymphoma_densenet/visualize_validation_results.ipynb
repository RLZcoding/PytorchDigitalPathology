{
    "cells": [{
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Y1QzEbsQ2bVD"
            },
            "outputs": [],
            "source": ["from google.colab import drive\n", "drive.mount('/gdrive')\n", "%cd /gdrive\n", "%cd My\\ Drive/PytorchDigitalPathology/google-collab-version/PytorchDigitalPathology/classification_lymphoma_densenet/"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ShVmGazZ2PBx"
            },
            "outputs": [],
            "source": ["#v3.classification\n", "#28/11/2018\n", "\n", "dataname=\"lymphoma\"\n", "gpuid=0\n", "\n", "patch_size=224 #should match the value used to train the network\n", "batch_size=1 #nicer to have a single batch so that we can iterately view the output, while not consuming too much \n", "nprint = 2 # number of results to show "]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jCHFkj812vYC"
            },
            "outputs": [],
            "source": ["!pip install tensorboardX"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "zdobz9cs2PB1"
            },
            "outputs": [],
            "source": ["# https://github.com/jvanvugt/pytorch-unet\n", "#torch.multiprocessing.set_start_method(\"fork\")\n", "import random, sys\n", "import cv2\n", "import glob\n", "import math\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import os\n", "import scipy.ndimage\n", "import time\n", "\n", "import tables\n", "from sklearn.metrics import confusion_matrix\n", "from tensorboardX import SummaryWriter\n", "\n", "import torch\n", "import torch.nn.functional as F\n", "from torch import nn\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torchvision.models import DenseNet\n", "\n", "import PIL\n", "\n"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "OdSxdNOz2PB4"
            },
            "outputs": [],
            "source": ["print(torch.cuda.get_device_properties(gpuid))\n", "torch.cuda.set_device(gpuid)\n", "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Yu7GD6rM2PB8"
            },
            "outputs": [],
            "source": ["checkpoint = torch.load(f\"{dataname}_densenet_best_model.pth\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "M5Ra3lHk2PB_"
            },
            "outputs": [],
            "source": ["#load the model, note that the paramters are coming from the checkpoint, since the architecture of the model needs to exactly match the weights saved\n", "\n", "model = DenseNet(growth_rate=checkpoint[\"growth_rate\"], block_config=checkpoint[\"block_config\"],\n", "                 num_init_features=checkpoint[\"num_init_features\"], bn_size=checkpoint[\"bn_size\"], drop_rate=checkpoint[\"drop_rate\"], num_classes=checkpoint[\"num_classes\"]).to(device)\n", "\n", "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")\n", "model.load_state_dict(checkpoint[\"model_dict\"])"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "sE_MQRTQ2PCC"
            },
            "outputs": [],
            "source": ["#this defines our dataset class which will be used by the dataloader\n", "class Dataset(object):\n", "    def __init__(self, fname ,img_transform=None):\n", "        #nothing special here, just internalizing the constructor parameters\n", "        self.fname=fname\n", "\n", "        self.img_transform=img_transform\n", "        \n", "        self.tables=tables.open_file(self.fname)\n", "        self.classsizes=self.tables.root.classsizes[:]\n", "        self.nitems=self.tables.root.imgs.shape[0]\n", "        self.tables.close()\n", "        \n", "        self.imgs = None\n", "        self.labels = None\n", "        \n", "    def __getitem__(self, index):\n", "        #opening should be done in __init__ but seems to be\n", "        #an issue with multithreading so doing here\n", "        if(self.imgs is None): #open in thread\n", "            self.tables=tables.open_file(self.fname)\n", "            self.imgs=self.tables.root.imgs\n", "            self.labels=self.tables.root.labels\n", "       \n", "        #get the requested image and mask from the pytable\n", "        img = self.imgs[index,:,:,:]\n", "        label = self.labels[index]\n", "        \n", "        img_new = img\n", "        \n", "        if self.img_transform is not None:\n", "            img_new = self.img_transform(img)\n", "\n", "\n", "        return img_new, label, img\n", "    def __len__(self):\n", "        return self.nitems"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "kPXqFbBb2PCE"
            },
            "outputs": [],
            "source": ["#probably only want to crop data to right size and otherwise not alter data during validation process\n", "img_transform = transforms.Compose([\n", "     transforms.ToPILImage(),\n", "#     transforms.RandomVerticalFlip(),\n", "#     transforms.RandomHorizontalFlip(),\n", "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), \n", "#     transforms.RandomResizedCrop(size=patch_size),\n", "#     transforms.RandomRotation(180),\n", "#     transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=.5),\n", "#     transforms.RandomGrayscale(),\n", "    transforms.ToTensor()\n", "    ])\n", "\n", "phases=[\"val\"]\n", "dataset={}\n", "dataLoader={}\n", "for phase in phases: #now for each of the phases, we're creating the dataloader\n", "                     #interestingly, given the batch size, i've not seen any improvements from using a num_workers>0\n", "    \n", "    dataset[phase]=Dataset(f\"./{dataname}_{phase}.pytable\", img_transform=img_transform)\n", "    dataLoader[phase]=DataLoader(dataset[phase], batch_size=batch_size, \n", "                                shuffle=True, num_workers=0, pin_memory=True) \n", "\n"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "MUm3q6A72PCI"
            },
            "outputs": [],
            "source": ["%matplotlib inline\n", "\n", "#set the model to evaluation mode, since we're only generating output and not doing any back propogation\n", "model.eval()\n", "confmatrix=np.zeros((checkpoint[\"num_classes\"],checkpoint[\"num_classes\"]))\n", "for ii , (X, label, img_orig) in enumerate(dataLoader['val']): #for each of the batches\n", "    X = X.to(device)  # [NBATCH, 3, H, W]\n", "    label = label.type('torch.LongTensor').to(device)  # [Nbatch, H, W] with class indices (0, 1)\n", "\n", "    output = model(X)  # [NBATCH, 2, H, W]\n", "\n", "    output=output.detach().squeeze().cpu().numpy() #get output and pull it to CPU\n", "    \n", "    print(output)\n", "    gt=label.cpu()[0]\n", "    pred=np.argmax(output)\n", "    confmatrix[gt,pred]+=1\n", "    print(f\"True class:\\t\\t{gt}\")\n", "    print(f\"Predicted class:\\t{pred}\")\n", "    print(\"--------\")\n", "#--- to visualize, uncomment here\n", "    fig, ax = plt.subplots(1,2, figsize=(10,4))  # 1 row, 2 columns\n", "    ax[0].imshow(np.moveaxis(X.detach().squeeze().cpu().numpy(),0,-1))\n", "    ax[1].imshow(img_orig.cpu().squeeze())\n", "    plt.show()\n", "#--- to limit the number of output, uncomment here\n", "    if(ii>nprint):\n", "        break\n", "        \n", "print(confmatrix)\n", "print(f\"Accuracty:\\t{confmatrix.trace()/confmatrix.sum()}\")"]
        }, {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "q6v8S83E2PCL"
            },
            "outputs": [],
            "source": [""]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "visualize_validation_results.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
